{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To showcase the power of PyTorch dynamic graphs, we will implement a very strange model: a fully-connected ReLU network that on each forward pass randomly chooses a number between 1 and 4 and has that many hidden layers, reusing the same weights multiple times to compute the innermost hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 637.8958129882812\n",
      "1 636.5549926757812\n",
      "2 632.8723754882812\n",
      "3 614.2298583984375\n",
      "4 627.6593017578125\n",
      "5 641.2145385742188\n",
      "6 621.7235717773438\n",
      "7 618.8411254882812\n",
      "8 610.5510864257812\n",
      "9 613.4346313476562\n",
      "10 489.9781188964844\n",
      "11 448.3780822753906\n",
      "12 608.1876831054688\n",
      "13 349.1754150390625\n",
      "14 541.2648315429688\n",
      "15 596.7841186523438\n",
      "16 603.661376953125\n",
      "17 601.8534545898438\n",
      "18 584.8062744140625\n",
      "19 577.8792724609375\n",
      "20 493.40399169921875\n",
      "21 557.2153930664062\n",
      "22 581.8602294921875\n",
      "23 573.761962890625\n",
      "24 125.92034912109375\n",
      "25 553.4913330078125\n",
      "26 540.7816772460938\n",
      "27 104.73466491699219\n",
      "28 364.9103088378906\n",
      "29 85.4630126953125\n",
      "30 480.9323425292969\n",
      "31 66.40955352783203\n",
      "32 390.08428955078125\n",
      "33 274.93994140625\n",
      "34 408.7766418457031\n",
      "35 231.0667266845703\n",
      "36 303.07470703125\n",
      "37 336.3463439941406\n",
      "38 90.8254165649414\n",
      "39 84.40387725830078\n",
      "40 64.11050415039062\n",
      "41 156.04241943359375\n",
      "42 282.8420104980469\n",
      "43 116.72854614257812\n",
      "44 32.92977523803711\n",
      "45 271.66632080078125\n",
      "46 94.31676483154297\n",
      "47 41.22771453857422\n",
      "48 255.2613983154297\n",
      "49 76.8858413696289\n",
      "50 101.02128601074219\n",
      "51 277.1725769042969\n",
      "52 61.750736236572266\n",
      "53 144.96975708007812\n",
      "54 158.07708740234375\n",
      "55 69.1592788696289\n",
      "56 122.40387725830078\n",
      "57 144.3069610595703\n",
      "58 47.544288635253906\n",
      "59 69.278076171875\n",
      "60 63.265296936035156\n",
      "61 104.72415161132812\n",
      "62 73.30101776123047\n",
      "63 36.61960983276367\n",
      "64 50.54600524902344\n",
      "65 41.93922805786133\n",
      "66 105.19036865234375\n",
      "67 24.50960350036621\n",
      "68 43.09254455566406\n",
      "69 27.58992576599121\n",
      "70 22.93596839904785\n",
      "71 25.733505249023438\n",
      "72 78.54888916015625\n",
      "73 30.321916580200195\n",
      "74 33.189247131347656\n",
      "75 21.507070541381836\n",
      "76 39.48192596435547\n",
      "77 19.578121185302734\n",
      "78 11.522281646728516\n",
      "79 13.17965316772461\n",
      "80 32.78932189941406\n",
      "81 23.83059310913086\n",
      "82 14.538129806518555\n",
      "83 15.697510719299316\n",
      "84 18.771034240722656\n",
      "85 16.065507888793945\n",
      "86 8.377510070800781\n",
      "87 49.1185417175293\n",
      "88 26.844022750854492\n",
      "89 21.603458404541016\n",
      "90 27.84024429321289\n",
      "91 8.410399436950684\n",
      "92 21.49228286743164\n",
      "93 27.146718978881836\n",
      "94 24.669198989868164\n",
      "95 10.932284355163574\n",
      "96 16.7935733795166\n",
      "97 9.094549179077148\n",
      "98 54.66677474975586\n",
      "99 39.10260009765625\n",
      "100 47.77333450317383\n",
      "101 28.710947036743164\n",
      "102 10.163801193237305\n",
      "103 11.020112037658691\n",
      "104 33.34262466430664\n",
      "105 20.58936882019043\n",
      "106 16.449085235595703\n",
      "107 8.96989917755127\n",
      "108 8.570089340209961\n",
      "109 7.2988786697387695\n",
      "110 13.818696022033691\n",
      "111 10.910665512084961\n",
      "112 6.203043460845947\n",
      "113 5.320714473724365\n",
      "114 3.9835147857666016\n",
      "115 3.4632604122161865\n",
      "116 3.566044330596924\n",
      "117 3.5376999378204346\n",
      "118 130.41319274902344\n",
      "119 6.943824291229248\n",
      "120 19.22588539123535\n",
      "121 130.80239868164062\n",
      "122 73.44461059570312\n",
      "123 63.87942123413086\n",
      "124 13.498188018798828\n",
      "125 16.356977462768555\n",
      "126 94.69046783447266\n",
      "127 65.9181137084961\n",
      "128 33.091453552246094\n",
      "129 48.48102569580078\n",
      "130 16.637481689453125\n",
      "131 37.05799865722656\n",
      "132 42.51622009277344\n",
      "133 36.3685417175293\n",
      "134 25.330066680908203\n",
      "135 22.26539421081543\n",
      "136 13.232361793518066\n",
      "137 26.072620391845703\n",
      "138 22.056453704833984\n",
      "139 25.440322875976562\n",
      "140 6.475974082946777\n",
      "141 29.206403732299805\n",
      "142 29.619483947753906\n",
      "143 19.92226791381836\n",
      "144 10.498910903930664\n",
      "145 35.10206604003906\n",
      "146 13.049983024597168\n",
      "147 12.111227989196777\n",
      "148 22.782381057739258\n",
      "149 32.50912857055664\n",
      "150 16.46881675720215\n",
      "151 9.439085960388184\n",
      "152 22.249156951904297\n",
      "153 8.777297973632812\n",
      "154 16.114370346069336\n",
      "155 13.911605834960938\n",
      "156 9.026920318603516\n",
      "157 7.401735782623291\n",
      "158 5.4615020751953125\n",
      "159 4.563478946685791\n",
      "160 7.282101154327393\n",
      "161 4.509110927581787\n",
      "162 7.700926303863525\n",
      "163 8.485345840454102\n",
      "164 17.862016677856445\n",
      "165 12.512069702148438\n",
      "166 13.166838645935059\n",
      "167 11.866414070129395\n",
      "168 14.779654502868652\n",
      "169 13.432639122009277\n",
      "170 5.028479099273682\n",
      "171 2.695693254470825\n",
      "172 15.313421249389648\n",
      "173 16.569583892822266\n",
      "174 77.19966125488281\n",
      "175 12.933267593383789\n",
      "176 35.923404693603516\n",
      "177 45.04833984375\n",
      "178 11.3183012008667\n",
      "179 23.118968963623047\n",
      "180 10.524198532104492\n",
      "181 30.979089736938477\n",
      "182 16.763601303100586\n",
      "183 40.412532806396484\n",
      "184 56.87618637084961\n",
      "185 20.739669799804688\n",
      "186 16.922138214111328\n",
      "187 36.07392120361328\n",
      "188 12.705709457397461\n",
      "189 8.736557960510254\n",
      "190 9.994131088256836\n",
      "191 10.92086410522461\n",
      "192 6.64990234375\n",
      "193 10.782615661621094\n",
      "194 7.980246543884277\n",
      "195 4.836198329925537\n",
      "196 16.330577850341797\n",
      "197 10.1328763961792\n",
      "198 9.325471878051758\n",
      "199 8.902312278747559\n",
      "200 17.07403564453125\n",
      "201 3.490968942642212\n",
      "202 6.221221923828125\n",
      "203 6.006553649902344\n",
      "204 6.614465713500977\n",
      "205 6.5367655754089355\n",
      "206 9.339044570922852\n",
      "207 7.481388092041016\n",
      "208 15.989703178405762\n",
      "209 4.753387928009033\n",
      "210 6.866259574890137\n",
      "211 14.205878257751465\n",
      "212 11.028740882873535\n",
      "213 6.0408854484558105\n",
      "214 4.313096523284912\n",
      "215 6.05892276763916\n",
      "216 24.208560943603516\n",
      "217 4.189294815063477\n",
      "218 3.247065305709839\n",
      "219 7.2635817527771\n",
      "220 9.166251182556152\n",
      "221 2.0729057788848877\n",
      "222 3.685940742492676\n",
      "223 3.0147249698638916\n",
      "224 2.0943148136138916\n",
      "225 3.8766884803771973\n",
      "226 4.352806568145752\n",
      "227 3.3268234729766846\n",
      "228 2.360260248184204\n",
      "229 1.6143416166305542\n",
      "230 3.0747230052948\n",
      "231 1.328696370124817\n",
      "232 1.8096296787261963\n",
      "233 2.017321825027466\n",
      "234 1.1438320875167847\n",
      "235 1.5888561010360718\n",
      "236 3.8622426986694336\n",
      "237 1.5759000778198242\n",
      "238 1.4449853897094727\n",
      "239 1.4368740320205688\n",
      "240 1.6155682802200317\n",
      "241 1.4708424806594849\n",
      "242 0.9985154271125793\n",
      "243 0.8191367387771606\n",
      "244 1.6743930578231812\n",
      "245 3.7055294513702393\n",
      "246 1.7143409252166748\n",
      "247 2.886685371398926\n",
      "248 0.7561829686164856\n",
      "249 3.008206367492676\n",
      "250 1.0944987535476685\n",
      "251 0.8885264992713928\n",
      "252 1.0316497087478638\n",
      "253 2.882981538772583\n",
      "254 0.8027917742729187\n",
      "255 1.5520329475402832\n",
      "256 0.6763997077941895\n",
      "257 0.5951851606369019\n",
      "258 2.2996485233306885\n",
      "259 0.3533548414707184\n",
      "260 0.2754334807395935\n",
      "261 1.1350747346878052\n",
      "262 0.30061957240104675\n",
      "263 0.8238803744316101\n",
      "264 1.896423101425171\n",
      "265 0.7353061437606812\n",
      "266 0.48561447858810425\n",
      "267 1.6893603801727295\n",
      "268 0.6945806741714478\n",
      "269 1.0485358238220215\n",
      "270 1.5724542140960693\n",
      "271 0.22261060774326324\n",
      "272 1.0177210569381714\n",
      "273 1.2707375288009644\n",
      "274 0.92726731300354\n",
      "275 0.8661437630653381\n",
      "276 0.8443722724914551\n",
      "277 0.7216385006904602\n",
      "278 0.8040873408317566\n",
      "279 0.5211687088012695\n",
      "280 0.39070671796798706\n",
      "281 0.3893296718597412\n",
      "282 1.9520399570465088\n",
      "283 1.8346792459487915\n",
      "284 0.4246979355812073\n",
      "285 0.3540467917919159\n",
      "286 0.296130895614624\n",
      "287 1.3907074928283691\n",
      "288 0.4727822542190552\n",
      "289 0.18328528106212616\n",
      "290 1.2499253749847412\n",
      "291 1.096417784690857\n",
      "292 0.6640801429748535\n",
      "293 1.0055640935897827\n",
      "294 0.9820705056190491\n",
      "295 0.12780410051345825\n",
      "296 0.13015815615653992\n",
      "297 0.1238628625869751\n",
      "298 0.8129661679267883\n",
      "299 0.1021420881152153\n",
      "300 0.738815188407898\n",
      "301 0.6397189497947693\n",
      "302 0.6391302943229675\n",
      "303 0.13379091024398804\n",
      "304 1.4375885725021362\n",
      "305 1.2748616933822632\n",
      "306 0.4990380108356476\n",
      "307 0.12189195305109024\n",
      "308 0.6801537871360779\n",
      "309 1.304988980293274\n",
      "310 1.01326584815979\n",
      "311 0.7055725455284119\n",
      "312 0.15900149941444397\n",
      "313 0.17013047635555267\n",
      "314 0.8870705962181091\n",
      "315 0.7607640624046326\n",
      "316 1.5336893796920776\n",
      "317 0.9455277323722839\n",
      "318 0.5053619742393494\n",
      "319 1.6618963479995728\n",
      "320 0.9771019220352173\n",
      "321 0.2609109580516815\n",
      "322 0.12804263830184937\n",
      "323 0.5860552191734314\n",
      "324 0.6763836145401001\n",
      "325 0.7935029864311218\n",
      "326 1.59345543384552\n",
      "327 0.27677640318870544\n",
      "328 0.5293124914169312\n",
      "329 0.13454794883728027\n",
      "330 1.2819229364395142\n",
      "331 0.09390223771333694\n",
      "332 0.10178118944168091\n",
      "333 0.11131713539361954\n",
      "334 0.6683192253112793\n",
      "335 0.4755153954029083\n",
      "336 0.4714691936969757\n",
      "337 0.16283944249153137\n",
      "338 0.4689922034740448\n",
      "339 1.368956208229065\n",
      "340 1.1869674921035767\n",
      "341 0.09103988111019135\n",
      "342 1.27677583694458\n",
      "343 0.9986521601676941\n",
      "344 0.1575160026550293\n",
      "345 0.17216306924819946\n",
      "346 1.5421334505081177\n",
      "347 0.7613759636878967\n",
      "348 0.7412223815917969\n",
      "349 1.0865026712417603\n",
      "350 0.3433258831501007\n",
      "351 0.301912397146225\n",
      "352 0.24978885054588318\n",
      "353 1.366255521774292\n",
      "354 0.1845370978116989\n",
      "355 0.18061400949954987\n",
      "356 1.0679353475570679\n",
      "357 1.4408658742904663\n",
      "358 1.079306721687317\n",
      "359 0.4407423138618469\n",
      "360 1.4919354915618896\n",
      "361 1.316845178604126\n",
      "362 0.27914297580718994\n",
      "363 0.853808581829071\n",
      "364 0.15827706456184387\n",
      "365 1.0929007530212402\n",
      "366 0.700829267501831\n",
      "367 0.5646460056304932\n",
      "368 1.0737587213516235\n",
      "369 0.09448728710412979\n",
      "370 0.09740516543388367\n",
      "371 0.3492830991744995\n",
      "372 0.8392377495765686\n",
      "373 0.7327920794487\n",
      "374 0.11519557982683182\n",
      "375 0.6203399300575256\n",
      "376 0.6578201055526733\n",
      "377 0.5875751376152039\n",
      "378 0.6385841965675354\n",
      "379 0.14764921367168427\n",
      "380 0.5168508887290955\n",
      "381 0.15656714141368866\n",
      "382 0.5637887716293335\n",
      "383 0.13227425515651703\n",
      "384 0.12943841516971588\n",
      "385 0.4171913266181946\n",
      "386 0.8585330843925476\n",
      "387 0.12202571332454681\n",
      "388 0.10550050437450409\n",
      "389 0.07753288000822067\n",
      "390 0.7095094919204712\n",
      "391 0.6999767422676086\n",
      "392 0.5010209679603577\n",
      "393 0.797015368938446\n",
      "394 0.6620985865592957\n",
      "395 0.45437151193618774\n",
      "396 0.6498343348503113\n",
      "397 0.24315449595451355\n",
      "398 0.19761788845062256\n",
      "399 1.4783101081848145\n",
      "400 0.6708914637565613\n",
      "401 0.7524235248565674\n",
      "402 0.9889792799949646\n",
      "403 0.5974549055099487\n",
      "404 0.6592684984207153\n",
      "405 0.7213289737701416\n",
      "406 0.6624217629432678\n",
      "407 0.12201986461877823\n",
      "408 0.3865711987018585\n",
      "409 0.8149556517601013\n",
      "410 0.330379456281662\n",
      "411 0.5810766220092773\n",
      "412 0.09029099345207214\n",
      "413 0.5939319729804993\n",
      "414 0.3389449715614319\n",
      "415 0.6432852149009705\n",
      "416 0.44210895895957947\n",
      "417 0.641257107257843\n",
      "418 0.35740119218826294\n",
      "419 0.4063207507133484\n",
      "420 0.3884655833244324\n",
      "421 0.540632963180542\n",
      "422 0.36209729313850403\n",
      "423 0.49012407660484314\n",
      "424 0.4475325644016266\n",
      "425 0.3479793071746826\n",
      "426 0.4771093726158142\n",
      "427 0.13406376540660858\n",
      "428 0.41144922375679016\n",
      "429 0.293789803981781\n",
      "430 0.37982794642448425\n",
      "431 0.3380434513092041\n",
      "432 0.6347525715827942\n",
      "433 0.6392093896865845\n",
      "434 0.08175861835479736\n",
      "435 0.07246065884828568\n",
      "436 0.38224610686302185\n",
      "437 0.4892690181732178\n",
      "438 0.41345876455307007\n",
      "439 0.37637925148010254\n",
      "440 0.31308263540267944\n",
      "441 0.2695097029209137\n",
      "442 0.2167023867368698\n",
      "443 0.902360200881958\n",
      "444 0.16235749423503876\n",
      "445 0.43314605951309204\n",
      "446 0.8612558245658875\n",
      "447 0.7754306793212891\n",
      "448 0.22289429605007172\n",
      "449 0.33289220929145813\n",
      "450 0.18447239696979523\n",
      "451 0.3414364159107208\n",
      "452 0.1355220079421997\n",
      "453 0.3546516001224518\n",
      "454 0.31665539741516113\n",
      "455 0.08804157376289368\n",
      "456 0.5315934419631958\n",
      "457 0.06643747538328171\n",
      "458 0.2864232361316681\n",
      "459 0.366767942905426\n",
      "460 0.47929883003234863\n",
      "461 0.3207356035709381\n",
      "462 0.27417275309562683\n",
      "463 0.5135475397109985\n",
      "464 0.061492253094911575\n",
      "465 0.33613085746765137\n",
      "466 0.0553182028234005\n",
      "467 0.05036308988928795\n",
      "468 0.26373282074928284\n",
      "469 0.4635804295539856\n",
      "470 0.3913113474845886\n",
      "471 0.37682411074638367\n",
      "472 0.3512919843196869\n",
      "473 0.30386003851890564\n",
      "474 0.054085902869701385\n",
      "475 0.05739498510956764\n",
      "476 0.057930488139390945\n",
      "477 0.3559572994709015\n",
      "478 0.33522847294807434\n",
      "479 0.8119784593582153\n",
      "480 0.23119360208511353\n",
      "481 0.567797839641571\n",
      "482 0.2705236077308655\n",
      "483 0.449063777923584\n",
      "484 0.21120111644268036\n",
      "485 0.12985213100910187\n",
      "486 0.6946930885314941\n",
      "487 0.14313679933547974\n",
      "488 0.09695082902908325\n",
      "489 0.3758445680141449\n",
      "490 0.14285391569137573\n",
      "491 0.14213894307613373\n",
      "492 0.3716250956058502\n",
      "493 0.12476352602243423\n",
      "494 0.12151441723108292\n",
      "495 0.11430460214614868\n",
      "496 0.09927342087030411\n",
      "497 0.6012645959854126\n",
      "498 0.5283186435699463\n",
      "499 0.1817757487297058\n"
     ]
    }
   ],
   "source": [
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
